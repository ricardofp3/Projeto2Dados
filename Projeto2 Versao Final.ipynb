{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Alan singer\n",
    "\n",
    "## Ricardo Peres\n",
    "\n",
    "## Victor Vazquez\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e\n",
    "    25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Clóvis Ricardo Peres\\Documents\\Cdados\\Projeto2Dados\\p2\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('spamham2019(1).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.head(5)\n",
    "len(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dados[int(len(dados)*0.25):]\n",
    "teste = dados[:int(len(dados)*0.25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpando a base de teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teste_email = teste[\"Email\"].str.lower().str.replace(',', '').str.replace('.', '').str.replace('?', '').str.replace('!', '')\\\n",
    ".str.replace('#', '').str.replace('||', '').str.replace('|', '').str.replace('//', '').str.replace('', '')\\\n",
    ".str.replace('\"', \"\").str.replace('\\n', \"\").str.replace('-', \"\").str.replace(']', \"\").str.replace('[', \"\")\\\n",
    ".str.replace('(', \"\").str.replace(')', \"\").str.replace('=', \"\").str.replace('*', \"\").str.replace('/', \"\")\\\n",
    ".str.replace('&', \"\").str.replace('$', \"\").str.replace('%', \"\").str.replace('ˆ', \"\").str.replace('*', \"\")\\\n",
    ".str.replace(';', \"\").str.replace(':', \"\").str.replace('  ', \"\").str.replace('   ', \"\").str.replace('    ', \"\")\\\n",
    ".str.replace('\\\\', \"\").str.replace('_', \"\")\n",
    "teste = pd.concat([teste_email,teste[\"Class\"]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpando a base de teste e separando em ham e spam:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_email = train[\"Email\"].str.lower().str.replace(',', '').str.replace('.', '').str.replace('?', '').str.replace('!', '')\\\n",
    ".str.replace('#', '').str.replace('||', '').str.replace('|', '').str.replace('//', '').str.replace('', '')\\\n",
    ".str.replace('\"', \"\").str.replace('\\n', \"\").str.replace('-', \"\").str.replace(']', \"\").str.replace('[', \"\")\\\n",
    ".str.replace('(', \"\").str.replace(')', \"\").str.replace('=', \"\").str.replace('*', \"\").str.replace('/', \"\")\\\n",
    ".str.replace('&', \"\").str.replace('$', \"\").str.replace('%', \"\").str.replace('ˆ', \"\").str.replace('*', \"\")\\\n",
    ".str.replace(';', \"\").str.replace(':', \"\").str.replace('  ', \"\").str.replace('   ', \"\").str.replace('    ', \"\")\\\n",
    ".str.replace('\\\\', \"\").str.replace('_', \"\")\n",
    "\n",
    "train_email_limpo = pd.concat([train_email,train[\"Class\"]],axis=1)\n",
    "train_ham_limpo = train_email_limpo[train_email_limpo.Class == \"ham\"]\n",
    "train_spam_limpo = train_email_limpo[train_email_limpo.Class == \"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotando cada base definida e limpa acima**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>oh ok</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>r we still meeting 4 dinner tonight</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>thats cool i am a gentleman and will treat you...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>shall i start from hear</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>then we wait 4 u lor no need 2 feel bad lar</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "1393                                              oh ok   ham\n",
       "1394                r we still meeting 4 dinner tonight   ham\n",
       "1395  thats cool i am a gentleman and will treat you...   ham\n",
       "1396                            shall i start from hear   ham\n",
       "1397        then we wait 4 u lor no need 2 feel bad lar   ham"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_email_limpo.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>oh ok</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>r we still meeting 4 dinner tonight</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>thats cool i am a gentleman and will treat you...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>shall i start from hear</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>then we wait 4 u lor no need 2 feel bad lar</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "1393                                              oh ok   ham\n",
       "1394                r we still meeting 4 dinner tonight   ham\n",
       "1395  thats cool i am a gentleman and will treat you...   ham\n",
       "1396                            shall i start from hear   ham\n",
       "1397        then we wait 4 u lor no need 2 feel bad lar   ham"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ham_limpo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>urgent important information for o2 user today...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>dear u've been invited to xchat this is our fi...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>congratulations ur awarded either å£500 of cd ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>for salearsenal dartboard good condition but n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>free 1st week entry 2 textpod 4 a chance 2 win...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "1406  urgent important information for o2 user today...  spam\n",
       "1413  dear u've been invited to xchat this is our fi...  spam\n",
       "1422  congratulations ur awarded either å£500 of cd ...  spam\n",
       "1429  for salearsenal dartboard good condition but n...  spam\n",
       "1443  free 1st week entry 2 textpod 4 a chance 2 win...  spam"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spam_limpo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printando o tamanho de cada base:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Limpa: 4179\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Limpa: {0}\".format(len(train_email_limpo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Ham: 3634\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Ham: {0}\".format(len(train_ham_limpo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Spam: 545\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Spam: {0}\".format(len(train_spam_limpo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Com todas as mensagens limpas foram criadas listas de palavras e de frases que foram completas através do código abaixo. Essas listas foram utilizadas para a criação de um dataset das palavras para que a probabilidade de aparição de cada palavra pudesse ser calulada (P(palavra)). E então após o cálculo das probabilidade as mesmas foram adicionadas a base contendo todas as palavras, a quantidade de vezes que cada uma aparece e a sua probabilidade de aparecer. Esses mesmo passos foram realizados para as palavras presentes em Ham e em Spam, para que pudessem ser calculadas as P(palavra/Ham) e P(palavra/Spam), porem somente com as palavras presentes em ham e em spam. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base toda:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62871"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frases = []\n",
    "palavras = []\n",
    "for frase in train_email_limpo.Email:\n",
    "    frases.append(frase.split(\" \"))\n",
    "    \n",
    "for e in frases:\n",
    "    for palavra in e:\n",
    "        palavras.append(palavra)\n",
    "        \n",
    "len(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GERAL: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>1649</td>\n",
       "      <td>18.936610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>1575</td>\n",
       "      <td>18.086817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>1508</td>\n",
       "      <td>17.317409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1059</td>\n",
       "      <td>12.161231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>969</td>\n",
       "      <td>11.127699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Quantidade  Probabilidade\n",
       "0       to        1649      18.936610\n",
       "1        i        1575      18.086817\n",
       "2      you        1508      17.317409\n",
       "3        a        1059      12.161231\n",
       "4      the         969      11.127699"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp_email = pd.DataFrame(data = palavras)\n",
    "qp_email.columns = [\"Palavras\"]\n",
    "q = qp_email[\"Palavras\"].value_counts()\n",
    "##################################################################################################################\n",
    "qp_frame = q.to_frame()\n",
    "qp_frame = q.reset_index()\n",
    "qp_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "qp_frame[\"Probabilidade\"] = 0\n",
    "###############################################################################################\n",
    "prob = []\n",
    "for i in range(len(qp_frame)): \n",
    "    prob.append((qp_frame[\"Quantidade\"][i]/len(qp_frame))*100)\n",
    "###############################################################################################\n",
    "print(\"GERAL: \")\n",
    "qp_frame[\"Probabilidade\"] = prob\n",
    "qp_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base ham:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_ham = []\n",
    "palavras_ham = []\n",
    "for frase in train_ham_limpo.Email:\n",
    "    frases_ham.append(frase.split(\" \"))\n",
    "for e in frases_ham:\n",
    "    for palavra in e:\n",
    "         palavras_ham.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>1544</td>\n",
       "      <td>22.507289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>1309</td>\n",
       "      <td>19.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1147</td>\n",
       "      <td>16.720117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>818</td>\n",
       "      <td>11.924198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>774</td>\n",
       "      <td>11.282799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Quantidade  Probabilidade\n",
       "0        i        1544      22.507289\n",
       "1      you        1309      19.081633\n",
       "2       to        1147      16.720117\n",
       "3      the         818      11.924198\n",
       "4        a         774      11.282799"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp_ham_email = pd.DataFrame(data = palavras_ham)\n",
    "qp_ham_email.columns = [\"Palavras\"]\n",
    "q_ham = qp_ham_email[\"Palavras\"].value_counts()\n",
    "##################################################################################################################\n",
    "qp_ham_frame = q_ham.to_frame()\n",
    "qp_ham_frame = q_ham.reset_index()\n",
    "qp_ham_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "qp_ham_frame[\"Probabilidade\"] = 0\n",
    "###############################################################################################\n",
    "prob_ham = []\n",
    "for i in range(len(qp_ham_frame)): \n",
    "    prob_ham.append((qp_ham_frame[\"Quantidade\"][i]/len(qp_ham_frame))*100)\n",
    "###############################################################################################\n",
    "print(\"HAM: \")\n",
    "qp_ham_frame[\"Probabilidade\"] = prob_ham\n",
    "qp_ham_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base spam:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_spam = []\n",
    "palavras_spam = []\n",
    "for frase in train_spam_limpo.Email:\n",
    "    frases_spam.append(frase.split(\" \"))\n",
    "for e in frases_spam:\n",
    "    for palavra in e:\n",
    "         palavras_spam.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>502</td>\n",
       "      <td>18.476261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>285</td>\n",
       "      <td>10.489510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>call</td>\n",
       "      <td>256</td>\n",
       "      <td>9.422157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your</td>\n",
       "      <td>202</td>\n",
       "      <td>7.434671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you</td>\n",
       "      <td>199</td>\n",
       "      <td>7.324255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Quantidade  Probabilidade\n",
       "0       to         502      18.476261\n",
       "1        a         285      10.489510\n",
       "2     call         256       9.422157\n",
       "3     your         202       7.434671\n",
       "4      you         199       7.324255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp_spam_email = pd.DataFrame(data = palavras_spam)\n",
    "qp_spam_email.columns = [\"Palavras\"]\n",
    "q_spam = qp_spam_email[\"Palavras\"].value_counts()\n",
    "##################################################################################################################\n",
    "qp_spam_frame = q_spam.to_frame()\n",
    "qp_spam_frame = q_spam.reset_index()\n",
    "qp_spam_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "qp_spam_frame[\"Probabilidade\"] = 0\n",
    "###############################################################################################\n",
    "prob_spam = []\n",
    "for i in range(len(qp_spam_frame)): \n",
    "    prob_spam.append((qp_spam_frame[\"Quantidade\"][i]/len(qp_spam_frame))*100)\n",
    "###############################################################################################\n",
    "print(\"SPAM: \")\n",
    "qp_spam_frame[\"Probabilidade\"] = prob_spam\n",
    "qp_spam_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sabendo o tamanho da base e o tamanho da base de spam e de ham é possível calcular a P(ham) e a P(spam), que serão utilizadas posteriormente para o outros cálculos **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanhos: Completo = 4179, Ham = 3634, Spam = 545\n",
      "\n",
      "Probabilidades: Ham = 86.95860253649198%, Spam = 13.041397463508016%\n"
     ]
    }
   ],
   "source": [
    "prob_spam = (len(train_spam_limpo)*100)/len(train_email_limpo)\n",
    "prob_ham = (len(train_ham_limpo)*100)/len(train_email_limpo)\n",
    "print(\"Tamanhos: Completo = {0}, Ham = {1}, Spam = {2}\".format( len(train_email_limpo),len(train_ham_limpo), len(train_spam_limpo)))\n",
    "print(\"\")\n",
    "print(\"Probabilidades: Ham = {0}%, Spam = {1}%\".format(prob_ham, prob_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Agora com as probabilidades previamente calculadas é possível descobrir a probabilidade de cada frase e a probabilidade de cada frase dado ham e spam, utilizando o método de laplace em que mesmo se a palavra nao estiver dentro de ham ou de spam a probabilidade nao sera zerada, pois para o calculo da mesma sempre adiciona-se 1 a probabilidade de cada palavra dado ham ou spam.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(ham/mensagem)=(p(mensagem/ham)*p(ham))\n",
    "\n",
    "p(spam/mensagem)=(p(mensgem/spam)*p(spam))\n",
    "\n",
    "\n",
    "p(mensagem/ham)=(1pm+1)/(len(ham)+len(total_semrepetir)) *(2pm)...)\n",
    "\n",
    "p(mensagem/spam)=(1pm)+1)/len(spam)+len(total_semrepetir)) *(2pm)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_laplanche(frase, typ, palavras):\n",
    "\n",
    "    frase_nv = frase.split(\" \")\n",
    "    qnt = [1]*len(frase_nv)\n",
    "    val = 1\n",
    "\n",
    "    for i in range(len(frase_nv)):\n",
    "        if frase_nv[i] in typ.Palavras.values.tolist():\n",
    "            \n",
    "            qnt[i] += typ.Quantidade[typ.loc[typ[\"Palavras\"] == frase_nv[i]].index[0]]\n",
    "    \n",
    "    prob = [i/(len(palavras) + len(qp_frame)) for i in qnt]\n",
    "    for r in prob: val *= r \n",
    "    return val*prob_ham/100 if len(typ) == len(qp_ham_frame) else float(val)*prob_spam/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def front(teste):\n",
    "    PF = 0\n",
    "    FN = 0\n",
    "    FV = 0\n",
    "    PV = 0\n",
    "\n",
    "    for i in range(len(teste)):\n",
    "        a = prob_laplanche(teste.Email[i], qp_ham_frame, palavras_ham)\n",
    "        ac = prob_laplanche(teste.Email[i], qp_spam_frame, palavras_spam)\n",
    "\n",
    "        comp = \"ham\" if a > ac else \"spam\"\n",
    "    \n",
    "        if comp == \"spam\" and teste.Class[i] != comp:\n",
    "            PF += 1 \n",
    "\n",
    "        if comp == \"ham\" and teste.Class[i] !=comp:\n",
    "            FN += 1\n",
    "\n",
    "        if comp == \"ham\" and teste.Class[i] == comp:\n",
    "            FV += 1\n",
    "\n",
    "        if comp == \"spam\" and teste.Class[i] == comp:\n",
    "            PV += 1\n",
    "\n",
    "        \n",
    "    return PF/len(teste),PV/len(teste),FV/len(teste),FN/len(teste), (FV + PV)/len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.024407753050969132,\n",
       " 0.01148600143575018,\n",
       " 0.8305814788226848,\n",
       " 0.13352476669059585,\n",
       " 0.842067480258435)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pf = falso positivo\n",
    "pv = positivo verdadeiro\n",
    "fv = negativo verdadeiro\n",
    "fn = falso negativo\n",
    "\n",
    "\n",
    "% de falsos positivos (mensagens marcadas como SPAM mas não são SPAM); 2%\n",
    "% de positivos verdadeiros (mensagens marcadas como SPAM e são SPAM); 1%\n",
    "% de negativos verdadeiros (mensagens marcadas como não SPAM e não são SPAM) 83%\n",
    "% de falsos negativos (mensagens marcadas como não SPAM mas são SPAM); 13%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repetindo todo o processo 10 mil vezes, passo 4 do arquivo do projeto no bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back(teste):\n",
    "    porce = 0\n",
    "    for i in range(len(teste)):\n",
    "        \n",
    "        a = prob_laplanche(teste.Email[i], qp_ham_frame, palavras_ham)\n",
    "        ac = prob_laplanche(teste.Email[i], qp_spam_frame, palavras_spam)\n",
    "\n",
    "        comp = \"ham\" if a > ac else \"spam\"\n",
    "    \n",
    "        if (comp == \"spam\" and teste.Class[i] == comp) or (comp == \"ham\" and teste.Class[i] == comp):\n",
    "            porce += 1\n",
    "\n",
    "        \n",
    "    return porce/len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8305814788226848,\n",
       " 0.8377602297200287,\n",
       " 0.8384781048097631,\n",
       " 0.8399138549892319,\n",
       " 0.8356066044508256,\n",
       " 0.8470926058865758,\n",
       " 0.8356066044508256,\n",
       " 0.8442211055276382]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentual = []\n",
    "\n",
    "for i in range(8):\n",
    "    l = dados.sample(frac=1)\n",
    "    train_10000 = l[int(len(l)*0.25):].reset_index().drop(['index'], axis=1)\n",
    "    teste_10000 = l[:int(len(l)*0.25)].reset_index().drop(['index'], axis=1)\n",
    "    ##########################\n",
    "    teste_email_10000 = teste_10000[\"Email\"].str.lower().str.replace(',', '').str.replace('.', '').str.replace('?', '').str.replace('!', '')\\\n",
    "    .str.replace('#', '').str.replace('||', '').str.replace('|', '').str.replace('//', '').str.replace('', '')\\\n",
    "    .str.replace('\"', \"\").str.replace('\\n', \"\").str.replace('-', \"\").str.replace(']', \"\").str.replace('[', \"\")\\\n",
    "    .str.replace('(', \"\").str.replace(')', \"\").str.replace('=', \"\").str.replace('*', \"\").str.replace('/', \"\")\\\n",
    "    .str.replace('&', \"\").str.replace('$', \"\").str.replace('%', \"\").str.replace('ˆ', \"\").str.replace('*', \"\")\\\n",
    "    .str.replace(';', \"\").str.replace(':', \"\").str.replace('  ', \"\").str.replace('   ', \"\").str.replace('    ', \"\")\\\n",
    "    .str.replace('\\\\', \"\").str.replace('_', \"\")\n",
    "    \n",
    "    teste_10000 = pd.concat([teste_email_10000,teste_10000[\"Class\"]],axis=1)\n",
    "    ##########################\n",
    "    train_email_10000 = train_10000[\"Email\"].str.lower().str.replace(',', '').str.replace('.', '').str.replace('?', '').str.replace('!', '')\\\n",
    "    .str.replace('#', '').str.replace('||', '').str.replace('|', '').str.replace('//', '').str.replace('', '')\\\n",
    "    .str.replace('\"', \"\").str.replace('\\n', \"\").str.replace('-', \"\").str.replace(']', \"\").str.replace('[', \"\")\\\n",
    "    .str.replace('(', \"\").str.replace(')', \"\").str.replace('=', \"\").str.replace('*', \"\").str.replace('/', \"\")\\\n",
    "    .str.replace('&', \"\").str.replace('$', \"\").str.replace('%', \"\").str.replace('ˆ', \"\").str.replace('*', \"\")\\\n",
    "    .str.replace(';', \"\").str.replace(':', \"\").str.replace('  ', \"\").str.replace('   ', \"\").str.replace('    ', \"\")\\\n",
    "    .str.replace('\\\\', \"\").str.replace('_', \"\")\n",
    "    \n",
    "    train_email_limpo_10000 = pd.concat([train_email_10000,train[\"Class\"]],axis=1)\n",
    "    train_ham_limpo_10000 = train_email_limpo_10000[train_email_limpo_10000.Class == \"ham\"]\n",
    "    train_spam_limpo_10000 = train_email_limpo_10000[train_email_limpo_10000.Class == \"spam\"]\n",
    "    ##########################\n",
    "    frases_spam = []\n",
    "    palavras_spam = []\n",
    "\n",
    "    for frase in train_spam_limpo_10000.Email:\n",
    "        frases_spam.append(str(frase).split(\" \"))\n",
    "    for e in frases_spam:\n",
    "        for palavra in e:\n",
    "             palavras_spam.append(palavra)\n",
    "\n",
    "    qp_spam_email = pd.DataFrame(data = palavras_spam)\n",
    "    qp_spam_email.columns = [\"Palavras\"]\n",
    "    q_spam = qp_spam_email[\"Palavras\"].value_counts()\n",
    "    qp_spam_frame = q_spam.to_frame()\n",
    "    qp_spam_frame = q_spam.reset_index()\n",
    "    qp_spam_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "    \n",
    "    ##################\n",
    "    frases_ham = []\n",
    "    palavras_ham = []\n",
    "    for frase in train_ham_limpo_10000.Email:\n",
    "        frases_ham.append(str(frase).split(\" \"))\n",
    "    for e in frases_ham:\n",
    "        for palavra in e:\n",
    "             palavras_ham.append(palavra)\n",
    "            \n",
    "    qp_ham_email = pd.DataFrame(data = palavras_ham)\n",
    "    qp_ham_email.columns = [\"Palavras\"]\n",
    "    q_ham = qp_ham_email[\"Palavras\"].value_counts()\n",
    "    qp_ham_frame = q_ham.to_frame()\n",
    "    qp_ham_frame = q_ham.reset_index()\n",
    "    qp_ham_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "    \n",
    "    percentual.append(back(teste_10000))\n",
    "\n",
    "percentual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 2., 2., 1., 0., 0., 1., 1.]),\n",
       " array([0.83058148, 0.83223259, 0.8338837 , 0.83553482, 0.83718593,\n",
       "        0.83883704, 0.84048816, 0.84213927, 0.84379038, 0.84544149,\n",
       "        0.84709261]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(percentual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise\n",
    "\n",
    "Analisando os resultados obtidos é possível concluir que o classificador conseguiu um total de acertos de aproximadamente 83% dos negativos verdadeiros ou seja: Marcou como não spam emails que não são spam, o que pode ser considerado um bom resultado mas com espaço para melhoras. Em contrapartida, o mesmo obteve apenas 1% de acerto para positivos verdadeiros, que são emails marcados como spam e são de fato spam.\n",
    "\n",
    "Quando maior a base de dados melhor funciona o classificador Naive-Bayes, portanto, a acurácia do modelo apresentado poderia ter sido melhorada utilizando uma base de dados ainda maior.\n",
    "\n",
    "Um dos fatores mais importantes que comprovam o sucesso, em parte, do modelo implementado é a baixa porcentagem de falsos positivos (cerca de 2%). Os falsos positivos classificam um não spam como spam, o que pode representar insatisfação dos usuários. \n",
    "\n",
    "Um ponto preocupante é a porcentagem de cerca de 13% para os falsos negativos que podem ser extremamente prejudiciais para o classificador, umas vez que marcam como não spam, um email que é spam. \n",
    "\n",
    "Desta forma, pensando em um ambiente empresarial, onde o objetivo é a satisfação do cliente (para que se possa obter lucro), os falsos positivos e negativo devem ter probabilidades muito baixas.\n",
    "\n",
    "Uma das desvantagens de se trabalhar com uma única divisão da base de dados em treinamento\n",
    "e  teste é que não é possível obter confiança elevada no modelo, já que as definições e palavras que são frequentes em emails de spam podem mudar diariamente, considerando o alto fluxo de dados na rede, tornando o classificar desatualizado rapidamente.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
