{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Alan singer\n",
    "\n",
    "## Ricardo Peres\n",
    "\n",
    "## Victor Vazquez\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e\n",
    "    25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Clóvis Ricardo Peres\\Desktop\\Projeto2Dados-master\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('spamham2019(1).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.head(5)\n",
    "len(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dados[int(len(dados)*0.25):]\n",
    "teste = dados[:int(len(dados)*0.25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpando a base de teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teste_email = teste[\"Email\"].str.lower().str.replace(',', '').str.replace('.', '').str.replace('?', '').str.replace('!', '')\\\n",
    ".str.replace('#', '').str.replace('||', '').str.replace('|', '').str.replace('//', '').str.replace('', '')\\\n",
    ".str.replace('\"', \"\").str.replace('\\n', \"\").str.replace('-', \"\").str.replace(']', \"\").str.replace('[', \"\")\\\n",
    ".str.replace('(', \"\").str.replace(')', \"\").str.replace('=', \"\").str.replace('*', \"\").str.replace('/', \"\")\\\n",
    ".str.replace('&', \"\").str.replace('$', \"\").str.replace('%', \"\").str.replace('ˆ', \"\").str.replace('*', \"\")\\\n",
    ".str.replace(';', \"\").str.replace(':', \"\").str.replace('  ', \"\").str.replace('   ', \"\").str.replace('    ', \"\")\\\n",
    ".str.replace('\\\\', \"\").str.replace('_', \"\")\n",
    "teste = pd.concat([teste_email,teste[\"Class\"]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpando a base de teste e separando em ham e spam:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_email = train[\"Email\"].str.lower().str.replace(',', '').str.replace('.', '').str.replace('?', '').str.replace('!', '')\\\n",
    ".str.replace('#', '').str.replace('||', '').str.replace('|', '').str.replace('//', '').str.replace('', '')\\\n",
    ".str.replace('\"', \"\").str.replace('\\n', \"\").str.replace('-', \"\").str.replace(']', \"\").str.replace('[', \"\")\\\n",
    ".str.replace('(', \"\").str.replace(')', \"\").str.replace('=', \"\").str.replace('*', \"\").str.replace('/', \"\")\\\n",
    ".str.replace('&', \"\").str.replace('$', \"\").str.replace('%', \"\").str.replace('ˆ', \"\").str.replace('*', \"\")\\\n",
    ".str.replace(';', \"\").str.replace(':', \"\").str.replace('  ', \"\").str.replace('   ', \"\").str.replace('    ', \"\")\\\n",
    ".str.replace('\\\\', \"\").str.replace('_', \"\")\n",
    "\n",
    "train_email_limpo = pd.concat([train_email,train[\"Class\"]],axis=1)\n",
    "train_ham_limpo = train_email_limpo[train_email_limpo.Class == \"ham\"]\n",
    "train_spam_limpo = train_email_limpo[train_email_limpo.Class == \"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotando cada base definida e limpa acima**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>oh ok</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>r we still meeting 4 dinner tonight</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>thats cool i am a gentleman and will treat you...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>shall i start from hear</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>then we wait 4 u lor no need 2 feel bad lar</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "1393                                              oh ok   ham\n",
       "1394                r we still meeting 4 dinner tonight   ham\n",
       "1395  thats cool i am a gentleman and will treat you...   ham\n",
       "1396                            shall i start from hear   ham\n",
       "1397        then we wait 4 u lor no need 2 feel bad lar   ham"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_email_limpo.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>oh ok</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>r we still meeting 4 dinner tonight</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>thats cool i am a gentleman and will treat you...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>shall i start from hear</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>then we wait 4 u lor no need 2 feel bad lar</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "1393                                              oh ok   ham\n",
       "1394                r we still meeting 4 dinner tonight   ham\n",
       "1395  thats cool i am a gentleman and will treat you...   ham\n",
       "1396                            shall i start from hear   ham\n",
       "1397        then we wait 4 u lor no need 2 feel bad lar   ham"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ham_limpo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>urgent important information for o2 user today...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>dear u've been invited to xchat this is our fi...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>congratulations ur awarded either å£500 of cd ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>for salearsenal dartboard good condition but n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>free 1st week entry 2 textpod 4 a chance 2 win...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "1406  urgent important information for o2 user today...  spam\n",
       "1413  dear u've been invited to xchat this is our fi...  spam\n",
       "1422  congratulations ur awarded either å£500 of cd ...  spam\n",
       "1429  for salearsenal dartboard good condition but n...  spam\n",
       "1443  free 1st week entry 2 textpod 4 a chance 2 win...  spam"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spam_limpo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printando o tamanho de cada base:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Limpa: 4179\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Limpa: {0}\".format(len(train_email_limpo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Ham: 3634\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Ham: {0}\".format(len(train_ham_limpo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Spam: 545\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Spam: {0}\".format(len(train_spam_limpo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Com todas as mensagens limpas foram criadas listas de palavras e de frases que foram completas através do código abaixo. Essas listas foram utilizadas para a criação de um dataset das palavras para que a probabilidade de aparição de cada palavra pudesse ser calulada (P(palavra)). E então após o cálculo das probabilidade as mesmas foram adicionadas a base contendo todas as palavras, a quantidade de vezes que cada uma aparece e a sua probabilidade de aparecer. Esses mesmo passos foram realizados para as palavras presentes em Ham e em Spam, para que pudessem ser calculadas as P(palavra/Ham) e P(palavra/Spam), porem somente com as palavras presentes em ham e em spam. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base toda:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62871"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frases = []\n",
    "palavras = []\n",
    "for frase in train_email_limpo.Email:\n",
    "    frases.append(frase.split(\" \"))\n",
    "    \n",
    "for e in frases:\n",
    "    for palavra in e:\n",
    "        palavras.append(palavra)\n",
    "        \n",
    "len(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GERAL: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>1649</td>\n",
       "      <td>18.936610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>1575</td>\n",
       "      <td>18.086817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>1508</td>\n",
       "      <td>17.317409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1059</td>\n",
       "      <td>12.161231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>969</td>\n",
       "      <td>11.127699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Quantidade  Probabilidade\n",
       "0       to        1649      18.936610\n",
       "1        i        1575      18.086817\n",
       "2      you        1508      17.317409\n",
       "3        a        1059      12.161231\n",
       "4      the         969      11.127699"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp_email = pd.DataFrame(data = palavras)\n",
    "qp_email.columns = [\"Palavras\"]\n",
    "q = qp_email[\"Palavras\"].value_counts()\n",
    "##################################################################################################################\n",
    "qp_frame = q.to_frame()\n",
    "qp_frame = q.reset_index()\n",
    "qp_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "qp_frame[\"Probabilidade\"] = 0\n",
    "###############################################################################################\n",
    "prob = []\n",
    "for i in range(len(qp_frame)): \n",
    "    prob.append((qp_frame[\"Quantidade\"][i]/len(qp_frame))*100)\n",
    "###############################################################################################\n",
    "print(\"GERAL: \")\n",
    "qp_frame[\"Probabilidade\"] = prob\n",
    "qp_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base ham:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_ham = []\n",
    "palavras_ham = []\n",
    "for frase in train_ham_limpo.Email:\n",
    "    frases_ham.append(frase.split(\" \"))\n",
    "for e in frases_ham:\n",
    "    for palavra in e:\n",
    "         palavras_ham.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>1544</td>\n",
       "      <td>22.507289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>1309</td>\n",
       "      <td>19.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1147</td>\n",
       "      <td>16.720117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>818</td>\n",
       "      <td>11.924198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>774</td>\n",
       "      <td>11.282799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Quantidade  Probabilidade\n",
       "0        i        1544      22.507289\n",
       "1      you        1309      19.081633\n",
       "2       to        1147      16.720117\n",
       "3      the         818      11.924198\n",
       "4        a         774      11.282799"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp_ham_email = pd.DataFrame(data = palavras_ham)\n",
    "qp_ham_email.columns = [\"Palavras\"]\n",
    "q_ham = qp_ham_email[\"Palavras\"].value_counts()\n",
    "##################################################################################################################\n",
    "qp_ham_frame = q_ham.to_frame()\n",
    "qp_ham_frame = q_ham.reset_index()\n",
    "qp_ham_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "qp_ham_frame[\"Probabilidade\"] = 0\n",
    "###############################################################################################\n",
    "prob_ham = []\n",
    "for i in range(len(qp_ham_frame)): \n",
    "    prob_ham.append((qp_ham_frame[\"Quantidade\"][i]/len(qp_ham_frame))*100)\n",
    "###############################################################################################\n",
    "print(\"HAM: \")\n",
    "qp_ham_frame[\"Probabilidade\"] = prob_ham\n",
    "qp_ham_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base spam:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_spam = []\n",
    "palavras_spam = []\n",
    "for frase in train_spam_limpo.Email:\n",
    "    frases_spam.append(frase.split(\" \"))\n",
    "for e in frases_spam:\n",
    "    for palavra in e:\n",
    "         palavras_spam.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>502</td>\n",
       "      <td>18.476261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>285</td>\n",
       "      <td>10.489510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>call</td>\n",
       "      <td>256</td>\n",
       "      <td>9.422157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your</td>\n",
       "      <td>202</td>\n",
       "      <td>7.434671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you</td>\n",
       "      <td>199</td>\n",
       "      <td>7.324255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Quantidade  Probabilidade\n",
       "0       to         502      18.476261\n",
       "1        a         285      10.489510\n",
       "2     call         256       9.422157\n",
       "3     your         202       7.434671\n",
       "4      you         199       7.324255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp_spam_email = pd.DataFrame(data = palavras_spam)\n",
    "qp_spam_email.columns = [\"Palavras\"]\n",
    "q_spam = qp_spam_email[\"Palavras\"].value_counts()\n",
    "##################################################################################################################\n",
    "qp_spam_frame = q_spam.to_frame()\n",
    "qp_spam_frame = q_spam.reset_index()\n",
    "qp_spam_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "qp_spam_frame[\"Probabilidade\"] = 0\n",
    "###############################################################################################\n",
    "prob_spam = []\n",
    "for i in range(len(qp_spam_frame)): \n",
    "    prob_spam.append((qp_spam_frame[\"Quantidade\"][i]/len(qp_spam_frame))*100)\n",
    "###############################################################################################\n",
    "print(\"SPAM: \")\n",
    "qp_spam_frame[\"Probabilidade\"] = prob_spam\n",
    "qp_spam_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sabendo o tamanho da base e o tamanho da base de spam e de ham é possível calcular a P(ham) e a P(spam), que serão utilizadas posteriormente para o outros cálculos **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanhos: Completo = 4179, Ham = 3634, Spam = 545\n",
      "\n",
      "Probabilidades: Ham = 86.95860253649198%, Spam = 13.041397463508016%\n"
     ]
    }
   ],
   "source": [
    "prob_spam = (len(train_spam_limpo)*100)/len(train_email_limpo)\n",
    "prob_ham = (len(train_ham_limpo)*100)/len(train_email_limpo)\n",
    "print(\"Tamanhos: Completo = {0}, Ham = {1}, Spam = {2}\".format( len(train_email_limpo),len(train_ham_limpo), len(train_spam_limpo)))\n",
    "print(\"\")\n",
    "print(\"Probabilidades: Ham = {0}%, Spam = {1}%\".format(prob_ham, prob_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Agora com as probabilidades previamente calculadas é possível descobrir a probabilidade de cada frase e a probabilidade de cada frase dado ham e spam, utilizando o método de laplace em que mesmo se a palavra nao estiver dentro de ham ou de spam a probabilidade nao sera zerada, pois para o calculo da mesma sempre adiciona-se 1 a probabilidade de cada palavra dado ham ou spam.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(ham/mensagem)=(p(mensagem/ham)*p(ham))\n",
    "\n",
    "p(spam/mensagem)=(p(mensgem/spam)*p(spam))\n",
    "\n",
    "\n",
    "p(mensagem/ham)=(1pm+1)/(len(ham)+len(total_semrepetir)) *(2pm)...)\n",
    "\n",
    "p(mensagem/spam)=(1pm)+1)/len(spam)+len(total_semrepetir)) *(2pm)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_laplanche(frase, typ, palavras):\n",
    "\n",
    "    frase_nv = frase.split(\" \")\n",
    "    qnt = [1]*len(frase_nv)\n",
    "    val = 1\n",
    "\n",
    "    for i in range(len(frase_nv)):\n",
    "        if frase_nv[i] in typ.Palavras.values.tolist():\n",
    "            \n",
    "            qnt[i] += typ.Quantidade[typ.loc[typ[\"Palavras\"] == frase_nv[i]].index[0]]\n",
    "    \n",
    "    prob = [i/(len(palavras) + len(qp_frame)) for i in qnt]\n",
    "    for r in prob: val *= r \n",
    "    return val*prob_ham/100 if len(typ) == len(qp_ham_frame) else float(val)*prob_spam/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def front(teste):\n",
    "    PF = 0\n",
    "    FN = 0\n",
    "    FV = 0\n",
    "    PV = 0\n",
    "\n",
    "    for i in range(len(teste)):\n",
    "        a = prob_laplanche(teste.Email[i], qp_ham_frame, palavras_ham)\n",
    "        ac = prob_laplanche(teste.Email[i], qp_spam_frame, palavras_spam)\n",
    "\n",
    "        comp = \"ham\" if a > ac else \"spam\"\n",
    "    \n",
    "        if comp == \"spam\" and teste.Class[i] != comp:\n",
    "            PF += 1 \n",
    "\n",
    "        if comp == \"ham\" and teste.Class[i] !=comp:\n",
    "            FN += 1\n",
    "\n",
    "        if comp == \"ham\" and teste.Class[i] == comp:\n",
    "            FV += 1\n",
    "\n",
    "        if comp == \"spam\" and teste.Class[i] == comp:\n",
    "            PV += 1\n",
    "\n",
    "        \n",
    "    return PF/len(teste),PV/len(teste),FV/len(teste),FN/len(teste), (FV + PV)/len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02512562814070352,\n",
       " 0.010050251256281407,\n",
       " 0.8298636037329504,\n",
       " 0.1349605168700646,\n",
       " 0.8399138549892319)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pf = falso positivo\n",
    "pv = positivo verdadeiro\n",
    "fv = negativo verdadeiro\n",
    "fn = falso negativo\n",
    "\n",
    "\n",
    "% de falsos positivos (mensagens marcadas como SPAM mas não são SPAM); \n",
    "% de positivos verdadeiros (mensagens marcadas como SPAM e são SPAM); \n",
    "% de negativos verdadeiros (mensagens marcadas como não SPAM e não são SPAM) \n",
    "% de falsos negativos (mensagens marcadas como não SPAM mas são SPAM);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repetindo todo o processo 10 mil vezes, passo 4 do arquivo do projeto no bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back(teste):\n",
    "    porce = 0\n",
    "    for i in range(len(teste)):\n",
    "        \n",
    "        a = prob_laplanche(teste.Email[i], qp_ham_frame, palavras_ham)\n",
    "        ac = prob_laplanche(teste.Email[i], qp_spam_frame, palavras_spam)\n",
    "\n",
    "        comp = \"ham\" if a > ac else \"spam\"\n",
    "    \n",
    "        if (comp == \"spam\" and teste.Class[i] == comp) or (comp == \"ham\" and teste.Class[i] == comp):\n",
    "            porce += 1\n",
    "\n",
    "        \n",
    "    return porce/len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8478104809763102,\n",
       " 0.842067480258435,\n",
       " 0.8485283560660445,\n",
       " 0.8463747307968413,\n",
       " 0.8320172290021536,\n",
       " 0.8435032304379038,\n",
       " 0.8628858578607322,\n",
       " 0.8585786073223259,\n",
       " 0.842067480258435,\n",
       " 0.8406317300789663]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentual = []\n",
    "\n",
    "for i in range(10):\n",
    "    l = dados.sample(frac=1)\n",
    "    train_10000 = l[int(len(l)*0.25):].reset_index().drop(['index'], axis=1)\n",
    "    teste_10000 = l[:int(len(l)*0.25)].reset_index().drop(['index'], axis=1)\n",
    "    ##########################\n",
    "    teste_email_10000 = teste_10000[\"Email\"].str.lower().str.replace(',', '').str.replace('.', '').str.replace('?', '').str.replace('!', '')\\\n",
    "    .str.replace('#', '').str.replace('||', '').str.replace('|', '').str.replace('//', '').str.replace('', '')\\\n",
    "    .str.replace('\"', \"\").str.replace('\\n', \"\").str.replace('-', \"\").str.replace(']', \"\").str.replace('[', \"\")\\\n",
    "    .str.replace('(', \"\").str.replace(')', \"\").str.replace('=', \"\").str.replace('*', \"\").str.replace('/', \"\")\\\n",
    "    .str.replace('&', \"\").str.replace('$', \"\").str.replace('%', \"\").str.replace('ˆ', \"\").str.replace('*', \"\")\\\n",
    "    .str.replace(';', \"\").str.replace(':', \"\").str.replace('  ', \"\").str.replace('   ', \"\").str.replace('    ', \"\")\\\n",
    "    .str.replace('\\\\', \"\").str.replace('_', \"\")\n",
    "    \n",
    "    teste_10000 = pd.concat([teste_email_10000,teste_10000[\"Class\"]],axis=1)\n",
    "    ##########################\n",
    "    train_email_10000 = train_10000[\"Email\"].str.lower().str.replace(',', '').str.replace('.', '').str.replace('?', '').str.replace('!', '')\\\n",
    "    .str.replace('#', '').str.replace('||', '').str.replace('|', '').str.replace('//', '').str.replace('', '')\\\n",
    "    .str.replace('\"', \"\").str.replace('\\n', \"\").str.replace('-', \"\").str.replace(']', \"\").str.replace('[', \"\")\\\n",
    "    .str.replace('(', \"\").str.replace(')', \"\").str.replace('=', \"\").str.replace('*', \"\").str.replace('/', \"\")\\\n",
    "    .str.replace('&', \"\").str.replace('$', \"\").str.replace('%', \"\").str.replace('ˆ', \"\").str.replace('*', \"\")\\\n",
    "    .str.replace(';', \"\").str.replace(':', \"\").str.replace('  ', \"\").str.replace('   ', \"\").str.replace('    ', \"\")\\\n",
    "    .str.replace('\\\\', \"\").str.replace('_', \"\")\n",
    "    \n",
    "    train_email_limpo_10000 = pd.concat([train_email_10000,train[\"Class\"]],axis=1)\n",
    "    train_ham_limpo_10000 = train_email_limpo_10000[train_email_limpo_10000.Class == \"ham\"]\n",
    "    train_spam_limpo_10000 = train_email_limpo_10000[train_email_limpo_10000.Class == \"spam\"]\n",
    "    ##########################\n",
    "    frases_spam = []\n",
    "    palavras_spam = []\n",
    "\n",
    "    for frase in train_spam_limpo_10000.Email:\n",
    "        frases_spam.append(str(frase).split(\" \"))\n",
    "    for e in frases_spam:\n",
    "        for palavra in e:\n",
    "             palavras_spam.append(palavra)\n",
    "\n",
    "    qp_spam_email = pd.DataFrame(data = palavras_spam)\n",
    "    qp_spam_email.columns = [\"Palavras\"]\n",
    "    q_spam = qp_spam_email[\"Palavras\"].value_counts()\n",
    "    qp_spam_frame = q_spam.to_frame()\n",
    "    qp_spam_frame = q_spam.reset_index()\n",
    "    qp_spam_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "    \n",
    "    ##################\n",
    "    frases_ham = []\n",
    "    palavras_ham = []\n",
    "    for frase in train_ham_limpo_10000.Email:\n",
    "        frases_ham.append(str(frase).split(\" \"))\n",
    "    for e in frases_ham:\n",
    "        for palavra in e:\n",
    "             palavras_ham.append(palavra)\n",
    "            \n",
    "    qp_ham_email = pd.DataFrame(data = palavras_ham)\n",
    "    qp_ham_email.columns = [\"Palavras\"]\n",
    "    q_ham = qp_ham_email[\"Palavras\"].value_counts()\n",
    "    qp_ham_frame = q_ham.to_frame()\n",
    "    qp_ham_frame = q_ham.reset_index()\n",
    "    qp_ham_frame.columns = [\"Palavras\", \"Quantidade\"]\n",
    "    \n",
    "    percentual.append(back(teste_10000))\n",
    "\n",
    "percentual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 1., 3., 1., 2., 0., 0., 1., 1.]),\n",
       " array([0.83201723, 0.83510409, 0.83819095, 0.84127782, 0.84436468,\n",
       "        0.84745154, 0.85053841, 0.85362527, 0.85671213, 0.85979899,\n",
       "        0.86288586]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(percentual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise\n",
    "\n",
    "Analisando os resultados obtidos é possível concluir que o classificador conseguiu um total de acertos de aproximadamente 83% dos negativos verdadeiros ou seja: Marcou como não spam e-mails que não são spam, o que pode ser considerado um bom resultado mas com espaço para melhoras. Em contrapartida, o mesmo obteve apenas 13% de acerto para positivos verdadeiros, que são e-mails marcados como spam e são de fato spam.\n",
    " \n",
    " \n",
    "Um dos fatores mais importantes que comprovam o sucesso, em parte, do modelo implementado é a baixa porcentagem de falsos positivos (cerca de 2%). Os falsos positivos classificam um não spam como spam, o que pode representar insatisfação dos usuários.\n",
    " \n",
    "Outro fator positivo é a porcentagem de cerca de 0.2% para os falsos negativos que podem ser extremamente prejudiciais para o classificador, umas vez que marcam como não spam, um email que é spam.\n",
    "\n",
    "Quanto maior a base de dados melhor funciona o classificador Naive-Bayes, portanto, a acurácia do modelo apresentado poderia ter sido melhorada utilizando uma base de dados ainda maior. Além disso, o número de repetições com que se calculam as probabilidades é de extrema importância para que se possa obter mais acurácia nos resultados do classificador. Por conta de limitações de hardware dos computadores, o número de repetições que utilizamos foi de 50, sendo que o número ideal para que se obtenha um bom modelo é de mais de 10 mil repetições.\n",
    " \n",
    "Desta forma, pensando em um ambiente empresarial, onde o objetivo é a satisfação do cliente (para que se possa obter lucro), os falsos positivos e negativo devem ter probabilidades muito baixas.\n",
    " \n",
    "Uma das desvantagens de se trabalhar com uma única divisão da base de dados em treinamento\n",
    "e  teste é que não é possível obter confiança elevada no modelo, já que as definições e palavras que são frequentes em emails de spam podem mudar diariamente, considerando o alto fluxo de dados na rede, tornando o classificar desatualizado rapidamente.\n",
    " \n",
    "Vale ressaltar que o classificador Naive-Bayes tem diversas utilidades além de classificar e-mail como spam ou não. Este tipo de classificador pode ser utilizado na área de medicina, meteorologia etc.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
